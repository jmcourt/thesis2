\chapter{Tools \& Methods}

\section{Instrumentation}

\par As the atmosphere of the Earth is opaque to X-rays and gamma-rays, studying high-energy astrophysical phenomena requires the use of space-based observatories.  A number of satellites dedicated to the study of X-rays have been launched over the years, starting with \textit{UHURU} in 1970 \citep{Giacconi_Uhuru} and, most recently, \textit{Hitomi} in 2016 \citep{Takahashi_Hitomi}.  We use data from a number of these missions in the research reported in this thesis; in particular we use data from the NASA satellites \textit{RXTE}, \textit{Swift} and \textit{Chandra}, the European satellites \textit{XMM-Newton} and \textit{INTEGRAL}, and the Japanese satellite \textit{Suzaku}.  This section introduces the instruments used in my studies, as well as the tools used to extract their data for further analysis.

\subsection{The \textit{Rossi X-Ray Timing Experiment}}

\par The \textit{Rossi X-Ray Timing Experiment}, more commonly known as \textit{RXTE}, was a NASA-operated satellite launched from Cape Canaveral on December 30, 1995 \citep{Bradt_RXTE}.  \textit{RXTE} was primarily an X-ray observatory, constructed specifically to study X-ray QPOs seen in X-ray Binaries \citep{Bradt_XTEaims}.  The observatory operated until January 5, 2012, when it was decommissioned.
\par \textit{RXTE} contained three instruments.  The main instruments consisted of two X-ray telescopes: the Proportional Counter Array (PCA, \citealp{Jahoda_PCA}) and the High Energy X-Ray Timing Experiment (HEXTE \citealp{Gruber_HEXTE}).  The satellite also carried an X-ray All-Sky Monitor (ASM, \citealp{Levine_ASM}).
\par PCA consisted of 5 Proportional Counting Units (PCUs) which were sensitive between $\sim2$--$60$\,keV.  The instrument had an excellent time resolution approaching 1\,$\mu$s, and an energy resolution of $\sim18\%$ at 6\,keV.  X-rays were guided onto the detectors by a collimator, resulting in an instrument field of view with a full-width half-maximum of 1$^\circ$.  There was a 6500\,cm$^2$ collecting area, and no angular resolution.
\par The HEXTE instrument provided complimentary coverage at higher energies, being sensitive between $\sim15$--$250$\,keV.  This instrument consisted 8 detectors, with a total collecting area of 1600\,cm$^2$, and had a similar field of view to that of PCA.  The time resolution is 8\,$\mu$s, and the energy resolution is 15\% at 60\,keV.
\par Finally, ASM was a soft X-ray all sky-monitor which covered 80\% of the sky every 90 minutes.  It was sensitive in the range 2--10\,keV, with a total collecting area of 90\,cm$^2$ and a spatial resolution of $3'\times15'$.  Due to its near continual coverage of the sky, ASM was excellent for long-term monitoring of transients in the soft X-ray sky.

\subsubsection{Data Formatting}

\par Much of the work in this thesis is based largely on data from PCA, which is freely available through the HEASARC archive maintained by NASA's Goddard Space Flight Centre\footnote{\url{https://heasarc.gsfc.nasa.gov/cgi-bin/W3Browse/w3browse.pl}}.  In PCA, as well as in other X-ray instruments, this data takes one of two forms:
\begin{itemize}
\item \textbf{Event-Mode Data:} A list of photon arrival times.  Depending on the instrument and observing mode, each of these times will have an associated channel, information about where in the detector the photon hit and a flag indicating the pattern that the photon made on the detector.
\item \textbf{Binned Data:} A list of evenly space time bins with the number of photons which arrived during each.  Depending on the instrument and observing mode, this may be accompanied by some information on the channel distribution of photons arriving in each bin.
\end{itemize}
\par The channel a photon falls into is denoted by its energy, although the channel-to-energy conversion for a particular instrument changes over time as the instrument degrades or settings are altered.  The channel-to-energy conversions for PCA can be found at \url{https://heasarc.gsfc.nasa.gov/docs/xte/e-c_table.html}.
\par Both event-mode and binned-mode data are stored in a Flexible Image Transit System (\texttt{.fits}) format.  This is a hierarchical data format consisting of a number of `Header Data Units' (HDUs), each of which contains data in some format and a header with details of the format.  In addition to either an event list or a table of binned data, these files also contain a list of Good Time Intervals (GTIs) during which the satellite was functioning normally, as well as an amount of housekeeping information such as the start and end times of the observation.
\par For PCA observations of faint objects, event mode data with full energy information (referred to as \texttt{goodxenon}-mode data) is generally available.  However when brighter objects were observed, telemetry constraints sometimes prevented this full information from being transmitted to Earth.  In this case, a number of data products are available; \texttt{Standard1} data (binned data with 0.125\,s time resolution but no energy information), \texttt{Standard2} data (binned data with 16\,s time resolution, divided into 128 bins by channel) and a number of other data products with various time and energy resolutions.  While \texttt{Standard2} data is useful for studying spectral variability over long timescales, it is not useful for studying the second-to-minute scale variability reported on in this thesis.  We used \texttt{goodxenon} data when available, as this allowed us to use the maximum possible time and energy resolutions, and various other datamodes including \texttt{Standard1} when \texttt{goodxenon} mode data was not available.

\subsubsection{Data Extraction \& Background Correction}

\par To perform science with PCA or other instruments, we must extract science products (such as lightcurves, power spectra and energy spectra) from the raw data.  Tools to create lightcurves and power spectra from PCA data are available as part of \texttt{FTOOLS} \footnote{\url{https://heasarc.gsfc.nasa.gov/ftools/}}, a free NASA-maintained suite of software for manipulating \texttt{.fits} formatted data.  These scripts make use of CALDB: a freely available database of calibration files provided by NASA for a number of active and historical X-ray telescopes \citep{}.  I also wrote my own software \texttt{PANTHEON} (Python ANalytical Tools for High-energy Event-data manipulatiON, \citealp{Court_PANTHEON}, presented in Appendix \ref{app:PAN}) to extract a number of additional products, such as power spectra and spectrograms.
\par In astronomy, the general way to subtract background from data is by selecting an empty piece of sky from the same observation as the source of interest, and then subtract one from the other.  However as PCA had no imaging capability, this is not possible to do with PCA data.  Instead, the \textit{RXTE} Guest Observatory Facility provides background models, which estimate the background of an observation based on the known X-ray background near the pointing direction and how the environment of the spacecraft changes over its orbit.  Two background models are available, for faint\footnote{\url{http://heasarc.gsfc.nasa.gov/FTP/xte/calib_data/pca_bkgd/Faint/pca_bkgd_cmfaintl7_eMv20051128.mdl}} ($<40$\,cts\,s$^{-1}$\,PCU$^{-1}$) and bright\footnote{\url{http://heasarc.gsfc.nasa.gov/FTP/xte/calib_data/pca_bkgd/Sky_VLE/pca_bkgd_cmbrightvle_eMv20051128.mdl}} ($>40$\,cts\,s$^{-1}$\,PCU$^{-1}$) sources; these can be used in conjunction with the \texttt{pcabackest} tool in \texttt{FTOOLS} to automatically subtract the estimated background from binned PCA data.
\par As the PCA background models do not subtract the contributions from other sources in the field of view, we also use a different technique to subtract background from observations of GRO J1744-28 (which is in a very crowded region of the sky near the Galactic centre).  To try and account for these other sources, we instead choose an observation of the region of GRO J1744-28 taken while this source was in quiescence; we assume that all photons in this observation must be from the particle background, the cosmic background or another source in the field of view.  Although this method does subtract some of the background contributed from other sources in the field, it must be treated with caution as these other sources are likely also variable.
\par To compare photometry data from PCA with data from other instruments, we normalise our data by the flux from the Crab nebula.  The Crab is a commonly used reference source in astronomy due to its apparent brightness and low variability across a wide portion of the electromagnetic spectrum.  To Crab-normalise PCA data from a given observation, we take the PCA observation of the Crab which is closest in time to the observation of interest and in the same gain epoch.  This follows the method employed in \citet{Altamirano_CrabNorm}.
\par Long-term lightcurves from ASM are available on the ASM Light Curves Overview web page (\url{http://xte.mit.edu/asmlc/ASM.html}) maintained by MIT.

\subsection{The \textit{Neil Gehrels Swift Observatory}}

\par The \textit{Neil Gehrels Swift Observatory}, formerly and more commonly known as \textit{Swift}, is a NASA-operated satellite launched from Cape Canaveral on November 20, 2004 \citep{Gehrels_Swift}.  \textit{Swift} was specifically designed to study Gamma Ray Bursts (GRBs), and is notable for its fast slew speed.
\par \textit{Swift} carries three instruments: the X-Ray Telescope (XRT, \citealp{Burrows_XRT}), the wide field-of-view hard X-ray Burst Alert Telescope (BAT, \citealp{Krimm_BAT}) and an UltraViolet/ Optical Telescope (UVOT, \citealp{Roming_UVOT}).  XRT is the primary instrument on \textit{Swift}: it is a focusing telescope with an effective energy range of 0.2--10\,keV.  Unlike PCA, XRT has imaging capabilities, with a field of view with a radius of 23.6' and an angular resolution of 18''.  The telescope has a minimum time resolution of 1.8\,ms and a minimum energy resolution of $\sim5$\% at 6\,keV.  XRT is operated in one of a number of `operating modes' during each observation, depending on the requirements of the observer.  The two main observing modes are:
\begin{enumerate}
\item Proportional Counting (PC) Mode: a full 2-dimensional image every 2.5\,s.
\item Windowed Timing (WT) Mode: a 1-dimensional image every 2.8\,ms.
\end{enumerate}
Both PC and WT modes also contain full energy information.
\par The main purpose of the wide area BAT telescope is to identify gamma ray bursts as soon as possible after they begin, so that \textit{Swift} can then slew to them for follow-up observation with XRT.  Due to its large field of view (1.4\,sr) and effective energy range of 15--150\,keV, BAT also provides us with long-term hard X-ray lightcurves of many bright sources in the X-ray sky.  It has a detecting area of 5200\,cm$^2$ and, when operating in survey mode, a time resolution of 5 minutes.
\par The final instrument, UVOT, is intended to take simultaneous optical and ultraviolet observations of sources observed with XRT.  It observes in the wavelength range between 170-650\,nm, and has 7 filters.

\subsubsection{Data Extraction}

\par XRT and ASM data on non-GRB transients are available via online portals maintained by the University of Leicester\footnote{\url{http://www.swift.ac.uk/user_objects/}} and the Goddard Space Flight Centre\footnote{\url{https://swift.gsfc.nasa.gov/results/transients/}} respectively.  The University of Leicester portal automatically extracts data lightcurves, spectra, images and source positions from raw XRT data of a given target, using the \texttt{xrtpipeline} provided in \texttt{FTOOLS}.  The Goddard Space Flight Centre provides ready-made 15--50\,keV lightcurves of 1019\footnote{Count as of May 2018.} X-ray transients, with cadences of either 1 per day or 1 per \textit{Swift} orbit.

\subsection{The \textit{X-Ray Multi-Mirror Mission}}

\par The \textit{X-Ray-Multi Mirror Mission} (\textit{XMM-Newton}, \citealp{Jansen_XMM}) is an ESA-operated satellite which was launched from Kourou, French Guiana on December 10, 1999, and is still operating almost 20 years later.  Like \textit{RXTE} and \textit{Swift}, \textit{XMM-Newton} also carries a number of separate instruments: namely the European Photon Imaging Camera (EPIC, \citealp{Bignami_EPIC}), the Reflection Grating Spectrometer (RGS, \citealp{denHerder_RGS}) and an Optical Monitor (OM, \citealp{Mason_OM}).  In the research presented in this thesis, I only make use of data from EPIC.
\par EPIC consists of three CCD cameras which work independently: two metal-oxide semiconductor CCD cameras (EPIC-MOS1 and EPIC-MOS2) and a single pn CCD camera at the focus of the telescope (EPIC-pn).  All cameras observe in the energy range 0.15--15\,keV, with a Field of View of 30', an angular resolution of 6'' and a maximum energy resolution of $\sim5$\%.  These can be operated in full frame, partial window or timing mode, each of which has a greater time resolution but narrower field of view than the last.  The maximum time resolution achievable by EPIC is 7\,$\mu$s which EPIC-pn is operated in burst mode; a special pn-only variant of timing mode.

\subsubsection{Data Extraction \& Processing}

\par \textit{XMM-Newton} data is extracted and processed using the \texttt{SAS} software \citep{Ibarra_sas} provided by ESA\footnote{\url{https://www.cosmos.esa.int/web/xmm-newton/sas}}.  These make use of the continuously updated Current Calibration Files provided by ESA.
\par The process of extracting basic data products from the EPIC instruments can be reduced to a number of steps:
\begin{itemize}
\item Use the \texttt{SAS} command \texttt{cifbuild} to create a Calibration Index File (CIF), containing pointers to the information in the CCF needed to reduce the chosen dataset.
\item Use the \texttt{SAS} command \texttt{odfingest} to create a summary file, containing data corrected by the CCF and by the EPIC housekeeping files.
\item Construct a photon event list from EPIC-MOS1 and EPIC-MOS2 using the \texttt{SAS} command \texttt{emproc}, or from EPIC-pn using the command \texttt{epproc}.
\end{itemize}
The event lists that result from this process can then be filtered using \texttt{evselect}, which allows the user to sort photons by arrival time, spatial co-ordinate and energy, among other parameters.  These filtered event lists can then be used to create science data products, such as lightcurves and energy spectra.

\subsection{\textit{Chandra}}

\subsection{\textit{Suzaku}}

\subsection{\textit{NuSTAR}}

\subsection{\textit{INTEGRAL}}

\section{Methods \& Techniques}

\par To extract meaningful physics from the data provided by the space-based observatories described above, we use a number of mathematical and analytical techniques.  We analyse three main properties of the data:
\begin{enumerate}
\item \textbf{Lightcurve Morphology:} Measuring the luminosity of an object, particularly in relation to its Eddington luminosity, and describing how this luminosity changes over time.
\item \textbf{Timing Analysis:} Using Fourier and Lomb-Scargle spectroscopy to identify periodic and quasi-periodic features in the data, and how these change with energy and time.
\item \textbf{Energy Spectral Analysis:}
\end{enumerate}
\par Some of the techniques we used to explore these properties are detailed in this section.

\subsection{Lightcurve Morphology}

\subsubsection{Lightcurve Folding}

\subsubsection{Flare-Finding Algorithm}
\label{sec:Flares}

\par The algorithm used to find flares is performed as such (see also Figure \ref{fig:BurstAlg}):

\begin{enumerate}
  \item Choose some threshold values $T_L$ and $T_H$.  Set the value of all datapoints below $T_L$ to zero.
  \item Retrieve the x-co-ordinate of the highest value remaining in the dataset.  Call this value $x_m$ and store it in a list.
  \item Set the value of point at $x_m$ to zero.
  \item Scan forwards from $x_m$.  If the selected point has a nonzero value, set it to zero and move to the next point.  If the selected point has a zero value, move to step (v).
  \item Scan backwards from $x_m$.  If the selected point has a nonzero value, set it to zero and move to the previous point.  If the selected point has a zero value, move to step (vi).
  \item Retrieve the y-co-ordinate of the highest value remaining in the dataset.  Call this $y_m$.
  \item If $y_m>T_H$, repeat steps (ii)--(vi).  If $y_m<T_H$, proceed to step (viii).
  \item Restore the original dataset.
  \item Retrieve the list of $x_m$ values found in step (ii).  Sort them in order of size.
  \item For each pair of adjacent $x_m$ values, find the x-coordinate of the datapoint between them with the lowest y-value.  Call these values $x_c$.
  \item This list of $x_c$ can now be used to demarcate the border between peaks.
\end{enumerate}

\begin{figure}
    \includegraphics[width=\columnwidth, trim = 0mm 30mm 0mm 28mm]{images/steps.eps}
    \captionsetup{singlelinecheck=off}
    \caption{From top-left: (i) An untouched data-set.  (ii) The dataset with all $y<T_L$ removed.  (iii) The dataset with all contiguous nonzero regions with $\max(y)<T_H$ removed.  (iv) The peak x-values $x_m$.  (v) The restored dataset with the peak x-values $x_m$ highlighted.  (vi) The boundaries between adjacent peaks.}
   \label{fig:BurstAlg}
\end{figure}

The values $T_L$ and $T_H$ can also be procedurally generated for a given piece of data:

\begin{enumerate}
  \item Select a small section of the dataset or a similar dataset (containing $\sim20$ peaks by eye) and note the location $x_e$ of all peaks found by eye.
  \item Let $P_L$ and $P_H$ be two arbitrary values in the range $[0,100]$.
  \item Let $T_L$ ($T_H$) be the $P_L$th ($P_H$th) percentile of the y-values of the subsection of dataset.
  \item Run the flare-finding algorithm up to step (ix).  Save the list of $x_m$.
  \item Split the dataset into bins on the x-axis such as the bin width $b\ll p$, where $p$ is the rough x-axis separation between peaks.
  \item For each bin, note if you found any value in $x_m$ falls in the bin and note if any value of $x_e$ falls in the bin.
  \item Using each bin as a trial, compute the Heidke Skill Score \citep{Heidke_SKSC} of the algorithm with the method of finding peaks by eye:
  \begin{equation}HSS = \frac{2(AD-BC)}{(A+B)(B+D)+(A+C)(C+D)}
  \label{eq:HSS}
  \end{equation}
  Where $A$ is the number of bins that contain both $x_e$ and $x_m$, $B$ ($C$) is the number of bins that contain only $x_m$ ($x_e$) and $D$ is the number of bins which contain neither \citep{Kok_YesNo}.
  \item Repeat steps (iii)--(vii) for all values of $P_H>P_L$ for $P_L$ and $P_H$ in $[1,100]$.  Use a sensible value for the resolution of $P_L$ and $P_H$.  Save the HSS for each pair of values
  \item Locate the maximum value of HSS, and note the $P_L$ and $P_H$ values used to generate it.  Use these values to generate your final $T_L$ and $T_H$ values.
\end{enumerate}

We show an example of Heidke skill score grid for this algorithm, applied to a Class IV observation, in Figure \ref{fig:Heidke}.

\begin{figure}
    \includegraphics[width=\columnwidth, trim = 0mm 10mm 0mm 10mm]{images/HSS_J.eps}
    \captionsetup{singlelinecheck=off}
    \caption{The Heidke Skill score of a Class IV observation of IGR J17091-3624 for a selection of different values $P_L$ and $P_H$.}
   \label{fig:Heidke}
\end{figure}

\subsubsection{Variable Period Lightcurve Folding}

\subsection{Timing Analysis}

\subsection{Energy Spectral Analysis}

\subsubsection{Phase-Resolved Spectroscopy}
\label{sec:phasresspec}

